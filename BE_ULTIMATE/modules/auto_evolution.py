#!/usr/bin/env python3
# auto_evolution.py - M√≥dulo de Auto-Evolu√ß√£o com M√∫ltiplas IAs
# Sistema que aprende, evolui e se otimiza automaticamente

import json
import os
import time
from datetime import datetime
import numpy as np

class AutoEvolutionAI:
    """
    Sistema de Auto-Evolu√ß√£o com M√∫ltiplas IAs
    - Aprendizado cont√≠nuo
    - Otimiza√ß√£o autom√°tica de estrat√©gias
    - Integra√ß√£o de m√∫ltiplos modelos
    - Meta-aprendizado
    """
    
    def __init__(self, config_path='evolution_state.json'):
        self.config_path = config_path
        self.state = self.load_state()
        self.models = {}
        self.performance_history = []
        
        # Inicializar modelos
        self.initialize_models()
        
        print("[Auto-Evolution] üß† Sistema de Auto-Evolu√ß√£o inicializado")
    
    def load_state(self):
        """Carrega estado do sistema."""
        if os.path.exists(self.config_path):
            with open(self.config_path, 'r') as f:
                return json.load(f)
        
        return {
            'version': '1.0.0',
            'iterations': 0,
            'total_learning_time': 0,
            'models_performance': {},
            'best_strategies': {},
            'knowledge_base': {},
            'evolution_log': []
        }
    
    def save_state(self):
        """Salva estado do sistema."""
        with open(self.config_path, 'w') as f:
            json.dump(self.state, f, indent=2)
    
    def initialize_models(self):
        """Inicializa modelos de IA."""
        self.models = {
            'betting_ai': {
                'name': 'Betting AI',
                'type': 'reinforcement_learning',
                'performance': 0.0,
                'confidence': 0.5,
                'iterations': 0
            },
            'trading_ai': {
                'name': 'Trading AI',
                'type': 'time_series_prediction',
                'performance': 0.0,
                'confidence': 0.5,
                'iterations': 0
            },
            'lottery_ai': {
                'name': 'Lottery AI',
                'type': 'pattern_recognition',
                'performance': 0.0,
                'confidence': 0.5,
                'iterations': 0
            },
            'strategy_optimizer': {
                'name': 'Strategy Optimizer',
                'type': 'genetic_algorithm',
                'performance': 0.0,
                'confidence': 0.5,
                'iterations': 0
            },
            'meta_learner': {
                'name': 'Meta Learner',
                'type': 'ensemble',
                'performance': 0.0,
                'confidence': 0.5,
                'iterations': 0
            }
        }
    
    def learn_from_result(self, model_name, action, result, reward):
        """Aprende com resultado de uma a√ß√£o."""
        if model_name not in self.models:
            return
        
        model = self.models[model_name]
        
        # Atualizar performance (m√©dia m√≥vel)
        alpha = 0.1  # Taxa de aprendizado
        model['performance'] = (1 - alpha) * model['performance'] + alpha * reward
        
        # Atualizar confian√ßa baseado em consist√™ncia
        if reward > 0:
            model['confidence'] = min(model['confidence'] + 0.01, 1.0)
        else:
            model['confidence'] = max(model['confidence'] - 0.01, 0.0)
        
        model['iterations'] += 1
        
        # Registrar no hist√≥rico
        self.performance_history.append({
            'model': model_name,
            'action': action,
            'result': result,
            'reward': reward,
            'performance': model['performance'],
            'timestamp': datetime.now().isoformat()
        })
        
        # Salvar estado
        self.state['models_performance'][model_name] = model['performance']
        self.save_state()
    
    def optimize_strategy(self, domain='betting'):
        """Otimiza estrat√©gia usando algoritmo gen√©tico."""
        print(f"[Auto-Evolution] üß¨ Otimizando estrat√©gia para {domain}...")
        
        # Popula√ß√£o inicial de estrat√©gias
        population_size = 10
        generations = 5
        
        population = self.generate_initial_population(domain, population_size)
        
        for gen in range(generations):
            # Avaliar fitness de cada estrat√©gia
            fitness_scores = [self.evaluate_strategy(s, domain) for s in population]
            
            # Selecionar melhores
            best_indices = np.argsort(fitness_scores)[-population_size//2:]
            best_strategies = [population[i] for i in best_indices]
            
            # Crossover e muta√ß√£o
            new_population = best_strategies.copy()
            
            while len(new_population) < population_size:
                parent1 = np.random.choice(best_strategies)
                parent2 = np.random.choice(best_strategies)
                
                child = self.crossover(parent1, parent2)
                child = self.mutate(child)
                
                new_population.append(child)
            
            population = new_population
            
            print(f"[Auto-Evolution] Gera√ß√£o {gen+1}/{generations} - Best fitness: {max(fitness_scores):.3f}")
        
        # Retornar melhor estrat√©gia
        final_fitness = [self.evaluate_strategy(s, domain) for s in population]
        best_strategy = population[np.argmax(final_fitness)]
        
        # Salvar melhor estrat√©gia
        self.state['best_strategies'][domain] = best_strategy
        self.save_state()
        
        return best_strategy
    
    def generate_initial_population(self, domain, size):
        """Gera popula√ß√£o inicial de estrat√©gias."""
        population = []
        
        for _ in range(size):
            strategy = {
                'risk_tolerance': np.random.uniform(0.01, 0.05),
                'confidence_threshold': np.random.uniform(0.5, 0.9),
                'max_stake_percent': np.random.uniform(0.02, 0.10),
                'stop_loss': np.random.uniform(0.05, 0.20),
                'take_profit': np.random.uniform(0.10, 0.50),
                'diversification': np.random.uniform(0.3, 0.8)
            }
            population.append(strategy)
        
        return population
    
    def evaluate_strategy(self, strategy, domain):
        """Avalia fitness de uma estrat√©gia."""
        # Simula√ß√£o simplificada
        # Em produ√ß√£o, seria backtesting real
        
        # Fatores de avalia√ß√£o
        risk_reward = strategy['take_profit'] / strategy['stop_loss']
        risk_management = 1 - strategy['risk_tolerance']
        confidence_quality = strategy['confidence_threshold']
        diversification_score = strategy['diversification']
        
        # Fitness score
        fitness = (
            risk_reward * 0.3 +
            risk_management * 0.2 +
            confidence_quality * 0.3 +
            diversification_score * 0.2
        )
        
        # Adicionar ru√≠do (simula√ß√£o de mercado)
        fitness += np.random.normal(0, 0.1)
        
        return max(0, fitness)
    
    def crossover(self, parent1, parent2):
        """Crossover entre duas estrat√©gias."""
        child = {}
        
        for key in parent1.keys():
            # 50% de chance de herdar de cada pai
            if np.random.random() < 0.5:
                child[key] = parent1[key]
            else:
                child[key] = parent2[key]
        
        return child
    
    def mutate(self, strategy, mutation_rate=0.2):
        """Muta√ß√£o de uma estrat√©gia."""
        mutated = strategy.copy()
        
        for key in mutated.keys():
            if np.random.random() < mutation_rate:
                # Muta√ß√£o: adicionar ru√≠do
                mutated[key] *= np.random.uniform(0.8, 1.2)
                
                # Garantir limites
                if key == 'risk_tolerance':
                    mutated[key] = np.clip(mutated[key], 0.01, 0.05)
                elif key == 'confidence_threshold':
                    mutated[key] = np.clip(mutated[key], 0.5, 0.9)
                elif key == 'max_stake_percent':
                    mutated[key] = np.clip(mutated[key], 0.02, 0.10)
                elif key == 'stop_loss':
                    mutated[key] = np.clip(mutated[key], 0.05, 0.20)
                elif key == 'take_profit':
                    mutated[key] = np.clip(mutated[key], 0.10, 0.50)
                elif key == 'diversification':
                    mutated[key] = np.clip(mutated[key], 0.3, 0.8)
        
        return mutated
    
    def ensemble_prediction(self, models_predictions):
        """Combina predi√ß√µes de m√∫ltiplos modelos."""
        # Weighted average baseado em performance
        weights = []
        predictions = []
        
        for model_name, prediction in models_predictions.items():
            if model_name in self.models:
                weight = self.models[model_name]['confidence']
                weights.append(weight)
                predictions.append(prediction)
        
        if not weights:
            return 0.5
        
        # Normalizar pesos
        weights = np.array(weights)
        weights = weights / weights.sum()
        
        # Predi√ß√£o ensemble
        ensemble_pred = np.average(predictions, weights=weights)
        
        return ensemble_pred
    
    def meta_learn(self):
        """Meta-aprendizado: aprender sobre o pr√≥prio aprendizado."""
        print("[Auto-Evolution] üéì Executando meta-aprendizado...")
        
        if len(self.performance_history) < 10:
            print("[Auto-Evolution] Dados insuficientes para meta-aprendizado")
            return
        
        # Analisar padr√µes de performance
        recent_history = self.performance_history[-100:]
        
        # Agrupar por modelo
        model_stats = {}
        
        for record in recent_history:
            model = record['model']
            
            if model not in model_stats:
                model_stats[model] = {
                    'rewards': [],
                    'success_rate': 0
                }
            
            model_stats[model]['rewards'].append(record['reward'])
        
        # Calcular estat√≠sticas
        insights = {}
        
        for model, stats in model_stats.items():
            rewards = stats['rewards']
            
            insights[model] = {
                'avg_reward': np.mean(rewards),
                'std_reward': np.std(rewards),
                'success_rate': sum(1 for r in rewards if r > 0) / len(rewards),
                'consistency': 1 / (1 + np.std(rewards))  # Menor std = mais consistente
            }
        
        # Identificar melhor modelo
        best_model = max(insights.items(), key=lambda x: x[1]['avg_reward'])[0]
        
        print(f"[Auto-Evolution] üèÜ Melhor modelo: {best_model}")
        print(f"[Auto-Evolution] üìä Reward m√©dio: {insights[best_model]['avg_reward']:.3f}")
        
        # Atualizar knowledge base
        self.state['knowledge_base']['meta_insights'] = insights
        self.state['knowledge_base']['best_model'] = best_model
        self.save_state()
        
        return insights
    
    def evolve(self):
        """Executa ciclo completo de evolu√ß√£o."""
        print("\n" + "="*60)
        print("[Auto-Evolution] üöÄ INICIANDO CICLO DE EVOLU√á√ÉO")
        print("="*60)
        
        start_time = time.time()
        
        # 1. Otimizar estrat√©gias
        domains = ['betting', 'trading', 'lottery']
        
        for domain in domains:
            best_strategy = self.optimize_strategy(domain)
            print(f"[Auto-Evolution] ‚úÖ Estrat√©gia otimizada para {domain}")
        
        # 2. Meta-aprendizado
        if len(self.performance_history) >= 10:
            insights = self.meta_learn()
        
        # 3. Atualizar estado
        self.state['iterations'] += 1
        elapsed_time = time.time() - start_time
        self.state['total_learning_time'] += elapsed_time
        
        # 4. Registrar evolu√ß√£o
        evolution_record = {
            'iteration': self.state['iterations'],
            'timestamp': datetime.now().isoformat(),
            'duration': elapsed_time,
            'models_performance': {k: v['performance'] for k, v in self.models.items()}
        }
        
        self.state['evolution_log'].append(evolution_record)
        self.save_state()
        
        print(f"\n[Auto-Evolution] ‚úÖ Ciclo {self.state['iterations']} completo em {elapsed_time:.2f}s")
        print("="*60)
    
    def print_status(self):
        """Imprime status do sistema."""
        print("\n" + "="*60)
        print("[Auto-Evolution] üìä STATUS DO SISTEMA")
        print("="*60)
        print(f"\nVers√£o: {self.state['version']}")
        print(f"Itera√ß√µes: {self.state['iterations']}")
        print(f"Tempo total de aprendizado: {self.state['total_learning_time']:.2f}s")
        
        print("\nü§ñ MODELOS:")
        for name, model in self.models.items():
            print(f"\n{model['name']}:")
            print(f"  Performance: {model['performance']:.3f}")
            print(f"  Confian√ßa: {model['confidence']*100:.1f}%")
            print(f"  Itera√ß√µes: {model['iterations']}")
        
        if 'best_model' in self.state.get('knowledge_base', {}):
            print(f"\nüèÜ Melhor Modelo: {self.state['knowledge_base']['best_model']}")
        
        print("="*60)


# Teste
if __name__ == "__main__":
    ai = AutoEvolutionAI()
    
    # Simular aprendizado
    print("[Test] Simulando aprendizado...")
    
    for i in range(20):
        model = np.random.choice(list(ai.models.keys()))
        action = f"action_{i}"
        result = np.random.choice(['win', 'loss'])
        reward = 1.0 if result == 'win' else -0.5
        
        ai.learn_from_result(model, action, result, reward)
    
    # Executar evolu√ß√£o
    ai.evolve()
    
    # Mostrar status
    ai.print_status()

